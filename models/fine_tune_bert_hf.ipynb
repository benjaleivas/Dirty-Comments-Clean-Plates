{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with hugging face wrapper for sanity check\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#training hyperparameters\n",
        "MAX_TOKENS = 512\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "\n",
        "# change to true to run per review\n",
        "EXPANDED = False\n",
        "\n",
        "model_checkpoint = \"distilbert/distilbert-base-uncased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "review_df = pd.read_csv('../data/split/train.csv', usecols=['Overall Compliance', 'reviews'])\n",
        "test_df = pd.read_csv('../data/split/test.csv', usecols=['Overall Compliance', 'reviews'])\n",
        "review_df['reviews'] = review_df['reviews'].apply(literal_eval)\n",
        "test_df['reviews'] = test_df['reviews'].apply(literal_eval)\n",
        "\n",
        "# test classifying at reivew level then resturant level\n",
        "if EXPANDED:\n",
        "    review_df = review_df.explode('reviews')\n",
        "    review_df = review_df.reset_index().drop(columns=['index'])\n",
        "\n",
        "    test_df = test_df.explode('reviews')\n",
        "    test_df = test_df.reset_index().drop(columns=['index'])\n",
        "\n",
        "train_ds = Dataset.from_pandas(review_df)\n",
        "test_df = Dataset.from_pandas(test_df)\n",
        "\n",
        "review_dataset = DatasetDict()\n",
        "\n",
        "review_dataset['train'] = train_ds\n",
        "review_dataset['test'] = test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_reviews(reviews):\n",
        "    cleaned = []\n",
        "    for review in reviews:\n",
        "        review = review.replace('\\n', ' ')\n",
        "        cleaned.append(re.sub(r\"[^a-zA-Z0-9]\", ' ', review).strip()) #may need to find a better way to do so\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "def extract_text_features(data):\n",
        "    output = {}\n",
        "    reviews = clean_reviews(data['reviews'])\n",
        "    output['text'] = \" \".join(reviews)\n",
        "    output['label'] = 0 if data['Overall Compliance'] == 'Yes' else 1\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def extract_expanded_text_features(data):\n",
        "    output = {}\n",
        "    review = data['reviews']\n",
        "    review = review.replace('\\n', ' ')\n",
        "    output['text'] = re.sub(r\"[^a-zA-Z0-9]\", ' ', review).strip()\n",
        "    output['label'] = 0 if data['Overall Compliance'] == 'Yes' else 1\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extract_function = extract_text_features\n",
        "\n",
        "if EXPANDED:\n",
        "    extract_function = extract_expanded_text_features\n",
        "\n",
        "review_dataset = review_dataset.map(extract_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "def tokenize(examples):\n",
        "    return tokenizer(examples[\"text\"], max_length=MAX_TOKENS, truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "token_dataset = review_dataset.map(tokenize, remove_columns=['Overall Compliance', 'reviews'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "id2label = {0: \"Pass\", 1: \"Fail\"}\n",
        "label2id = {\"Pass\": 0, \"Fail\": 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"base_bert_model\",\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=token_dataset[\"train\"],\n",
        "    eval_dataset=token_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "85ea4b3f8f8bbee1e23da4c155a93a1e9f6833b5217ca791a452f768bdc9cb7b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
