{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 16:51:56.845308: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 16:51:56.896164: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# with hugging face wrapper for sanity check\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training hyperparameters\n",
    "MAX_TOKENS = 512\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 1e-05\n",
    "\n",
    "# change to true to run per review\n",
    "EXPANDED = False\n",
    "\n",
    "model_checkpoint = \"distilbert/distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/models\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv('../data/split/train.csv', usecols=['Overall Compliance', 'reviews'])\n",
    "test_df = pd.read_csv('../data/split/test.csv', usecols=['Overall Compliance', 'reviews'])\n",
    "val_df = pd.read_csv('../data/split/val.csv', usecols=['Overall Compliance', 'reviews'])\n",
    "review_df['reviews'] = review_df['reviews'].apply(literal_eval)\n",
    "test_df['reviews'] = test_df['reviews'].apply(literal_eval)\n",
    "val_df['reviews'] = val_df['reviews'].apply(literal_eval)\n",
    "\n",
    "# test classifying at reivew level then resturant level\n",
    "if EXPANDED:\n",
    "    review_df = review_df.explode('reviews')\n",
    "    review_df = review_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "    test_df = test_df.explode('reviews')\n",
    "    test_df = test_df.reset_index().drop(columns=['index'])\n",
    "    \n",
    "    val_df = val_df.explode('reviews')\n",
    "    val_df = val_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "train_ds = Dataset.from_pandas(review_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "val_ds = Dataset.from_pandas(val_df)\n",
    "\n",
    "review_dataset = DatasetDict()\n",
    "\n",
    "review_dataset['train'] = train_ds\n",
    "review_dataset['test'] = test_ds\n",
    "review_dataset['val'] = val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(reviews):\n",
    "    cleaned = []\n",
    "    for review in reviews:\n",
    "        review = review.replace('\\n', ' ')\n",
    "        cleaned.append(re.sub(r\"[^a-zA-Z0-9]\", ' ', review).strip()) #may need to find a better way to do so\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "def extract_text_features(data):\n",
    "    output = {}\n",
    "    reviews = clean_reviews(data['reviews'])\n",
    "    output['text'] = \" \".join(reviews)\n",
    "    output['label'] = 0 if data['Overall Compliance'] == 'Yes' else 1\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def extract_expanded_text_features(data):\n",
    "    output = {}\n",
    "    review = data['reviews']\n",
    "    review = review.replace('\\n', ' ')\n",
    "    output['text'] = re.sub(r\"[^a-zA-Z0-9]\", ' ', review).strip()\n",
    "    output['label'] = 0 if data['Overall Compliance'] == 'Yes' else 1\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f726c21e050f4590a0efa056a7653c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1754 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c630065d814c6cb348c925071bf0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c43aaa14f6476cac879d8ac878a678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extract_function = extract_text_features\n",
    "\n",
    "if EXPANDED:\n",
    "    extract_function = extract_expanded_text_features\n",
    "\n",
    "review_dataset = review_dataset.map(extract_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], max_length=MAX_TOKENS, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f734dc1b9ff5416c96399570abc69397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1754 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2cf3729ad74eea9a8226e03fcbd8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dea5c1385c476f8bbf88c5388fb53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_dataset = review_dataset.map(tokenize, remove_columns=['Overall Compliance', 'reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "recall_metric = evaluate.load('recall')\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    return {'accuracy': accuracy, 'recall': recall, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"Pass\", 1: \"Fail\"}\n",
    "label2id = {\"Pass\": 0, \"Fail\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [440/440 05:06, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.472015</td>\n",
       "      <td>{'accuracy': 0.8205128205128205}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.465191</td>\n",
       "      <td>{'accuracy': 0.8205128205128205}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.458886</td>\n",
       "      <td>{'accuracy': 0.8205128205128205}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.458501</td>\n",
       "      <td>{'accuracy': 0.8205128205128205}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        4.0\n",
      "  total_flos               =   865563GF\n",
      "  train_loss               =     0.5201\n",
      "  train_runtime            = 0:05:07.54\n",
      "  train_samples_per_second =     22.813\n",
      "  train_steps_per_second   =      1.431\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"base_bert_model\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=token_dataset[\"train\"],\n",
    "    eval_dataset=token_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "trainer.log_metrics(\"train\", train_result.metrics)\n",
    "trainer.save_metrics(\"train\", train_result.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "metrics = trainer.evaluate(token_dataset['val'])\n",
    "\n",
    "file_path = \"base_bert_model/val_results.json\"\n",
    "\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(metrics, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r base_bert.zip base_bert_model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "85ea4b3f8f8bbee1e23da4c155a93a1e9f6833b5217ca791a452f768bdc9cb7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
