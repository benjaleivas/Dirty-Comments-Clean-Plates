{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Reviews\n",
    "\n",
    "This Jupyter Notebook creates fake reviews using ChatGPT, using different models (GPT-3.5, GPT-4), prompt engineering techniques (zero- vs few-shot prompts), restaurant and review characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base prompt:\n",
      "\n",
      "You attended a restaurant named REST_NAME.\n",
      "You rated your experience with NUM_STARS stars out of 5.\n",
      "Write a review of NUM_CHAR characters describing your experience.\n"
     ]
    }
   ],
   "source": [
    "#Dependencies\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "# from openai import openai, APIRemovedInV1\n",
    "# import openai # pip install openai==0.27.8\n",
    "\n",
    "#Directories\n",
    "os.chdir('/home/bleiva/capp30255/how_the_bear_got_a_C')\n",
    "output_dir = 'how_the_bear_got_a_C/chat_gpt'\n",
    "\n",
    "#OpenAI\n",
    "client = OpenAI(api_key='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')\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
    "\n",
    "#Base prompt\n",
    "with open('chat_gpt/base_prompt.txt', 'r') as file:\n",
    "    base_prompt = file.read()\n",
    "\n",
    "print(f'Base prompt:\\n\\n{base_prompt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_moments_of_attribute_distribution(dataset: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Finds review attributes from underlying distributions of real reviews.\n",
    "\n",
    "    Input:\n",
    "        - dataset (DataFrame): a pandas dataframe.\n",
    "    \n",
    "    Returns dictionary with attribute (str), moments (dict) pairs. \n",
    "    \"\"\"\n",
    "\n",
    "    #Create output structure\n",
    "    attr_moments = {'stars': None, 'text_length': None}\n",
    "\n",
    "    #Compute moments for rest of attributes\n",
    "    for attr in ['stars', 'text_length']:\n",
    "        attr_moments[attr] = {'mean': dataset[attr].mean(),\n",
    "                             'median': dataset[attr].median(), \n",
    "                             'std': dataset[attr].std()}\n",
    "\n",
    "    return attr_moments\n",
    "\n",
    "def create_fake_review_attributes(dataset: pd.DataFrame, attr_moments: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Creates attributes by drawing random value from empirical distribution.\n",
    "\n",
    "    Input:\n",
    "        - attribute_moments (dict): a dictionary of attribute, moments.\n",
    "    \n",
    "    Returns dictionary where each key, value is an attribute, value.\n",
    "    \"\"\"\n",
    "\n",
    "    #Create output structure\n",
    "    attrs = {'business_name': None, 'stars': None, 'text_length': None}\n",
    "\n",
    "    #Compute and store values\n",
    "    for key in ['text_length', 'stars', 'business_name']:\n",
    "        if key == 'text_length':\n",
    "            attr_value = round(abs(np.random.normal(attr_moments[key]['mean'], attr_moments[key]['std'])))\n",
    "            # print('picked_text_length:', attr_value)\n",
    "        elif key == 'stars':\n",
    "            choices = [1, 2, 3, 4, 5]\n",
    "            probs = [0.153, 0.078, 0.099, 0.208, 0.462] #from empirical distribution\n",
    "            attr_value = np.random.choice(choices, p=probs)\n",
    "            # print('picked_star:', attr_value)\n",
    "        elif key == 'business_name':\n",
    "            attr_value = np.random.choice(dataset[key])\n",
    "            # print('picked_name:', attr_value)\n",
    "        #Store in dictionary\n",
    "        attrs[key] = attr_value\n",
    "\n",
    "    return attrs\n",
    "\n",
    "def draw_reviews_from_verified_sample(dataset: pd.DataFrame, \n",
    "                                      num_draws: int, \n",
    "                                      attributes: dict) -> list:\n",
    "    \"\"\"\n",
    "    Takes a set of attributes and randomly draws verified reviews with those \n",
    "    characteristics.\n",
    "\n",
    "    Inputs:\n",
    "        - dataset (DataFrame): a pandas dataframe\n",
    "        - num_draws (int): number of reviews to extract from dataset\n",
    "        - attributes (dict): key, value pairs of attributes to filter from\n",
    "\n",
    "    Returns a list of reviews that match those attributes.        \n",
    "    \"\"\"\n",
    "\n",
    "    #Filter dataset\n",
    "    filtered_dataset = dataset[dataset['business_name'] == attributes['business_name']]\n",
    "    num_rows = filtered_dataset.shape[0]\n",
    "\n",
    "    #Pick reviews\n",
    "    if num_rows >= num_draws:\n",
    "        sampled_rows = filtered_dataset.sample(n=num_draws, replace=False)\n",
    "    else:\n",
    "        sampled_rows = filtered_dataset.sample(n=num_rows, replace=False)\n",
    "\n",
    "    examples = []\n",
    "    for _, row in sampled_rows.iterrows():\n",
    "        d = {'business_name': row['business_name'], 'stars': row['stars'], 'text_length': row['text_length'], 'text': row['text']}\n",
    "        examples.append(d)\n",
    "\n",
    "    return examples\n",
    "\n",
    "def generate_fake_review_prompt(dataset: pd.DataFrame,\n",
    "                                base_prompt: str,\n",
    "                                num_shots: int,\n",
    "                                attributes: dict) -> str:\n",
    "    \"\"\"\n",
    "    Takes review characteristics and outputs a fake review.\n",
    "    \n",
    "    Inputs:\n",
    "        - base_prompt (str): standard prompt to build from\n",
    "        - num_shots (int): number of examples to give in prompt\n",
    "        - review_length (int): max number of words contained in review\n",
    "        - restaurant (str): name of the restaurant that is getting reviewed\n",
    "        - num_stars (int): rating of the restaurant by the (fake) user\n",
    "        - useful (boolean): True if review is useful, False otherwise \n",
    "        - funny (boolean): True if review is funny, False otherwise\n",
    "        - cool (boolean):  True if review is cool, False otherwise  \n",
    "\n",
    "    Returns a prompt to generate fake review in ChatGPT's API.\n",
    "    \"\"\"\n",
    "\n",
    "    #Build prompt based on relevant variables\n",
    "    prompt = base_prompt.replace(\"REST_NAME\", attributes['business_name']) \\\n",
    "                        .replace(\"NUM_CHAR\", str(abs(attributes['text_length']))) \\\n",
    "                        .replace(\"NUM_STARS\", str(attributes['stars']))\n",
    "    #Zero-shot\n",
    "    if num_shots == 0:\n",
    "        return prompt\n",
    "    \n",
    "    #Few-shot\n",
    "    reviews = draw_reviews_from_verified_sample(dataset, num_shots, attributes)\n",
    "    few_shot_text = '\\n\\nConsider the examples below:\\n\\n'\n",
    "    count = 1\n",
    "    for i in range(len(reviews)):\n",
    "        few_shot_text += f\"##\\nExample {count}: Restaurant name = {reviews[i]['business_name']}; \" \\\n",
    "                        f\"Number of characters = {str(len(reviews[i]))}; \" \\\n",
    "                        f\"Number of stars = {str(reviews[i]['stars'])}.\\n\" \\\n",
    "                        f\"Review {count}: {reviews[i]['text']}.\\n##\"\n",
    "        count +=1\n",
    "\n",
    "    prompt = prompt+few_shot_text\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def make_api_calls(model: str, \n",
    "                  system_content: str, \n",
    "                  temperature: float, \n",
    "                  num_shots: int,\n",
    "                  dataset: pd.DataFrame\n",
    "                  ):\n",
    "    \"\"\"\n",
    "    Make calls to ChatGPT's API using a specific prompt, model, and temperature.\n",
    "\n",
    "    Inputs:\n",
    "        - model (str): model of OpenAI to use\n",
    "        - system_content (str): content of system role\n",
    "        - temperature (float): level of randomness of output\n",
    "        - num_shots (int): number of examples in prompt\n",
    "        - dataset (pd.DataFrame): DataFrame containing the dataset\n",
    "    \n",
    "    Returns a csv file where each row contains the statement and the output.\n",
    "    \"\"\"\n",
    "\n",
    "    fake_review_count = 0\n",
    "\n",
    "    if num_shots == 0:\n",
    "        shots = 'zero'\n",
    "    else:\n",
    "        shots = 'few'\n",
    "\n",
    "    attr_moments = find_moments_of_attribute_distribution(dataset)\n",
    "    attr_fake = create_fake_review_attributes(dataset, attr_moments)\n",
    "    fake_prompt = generate_fake_review_prompt(dataset, base_prompt, num_shots, attr_fake)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    csv_file_path = os.path.join(output_dir, f'fake_reviews_{model}_{num_shots}_shots.csv')\n",
    "\n",
    "    with open(csv_file_path, mode='a', newline='') as f:\n",
    "\n",
    "        # Create headers only if the file is empty\n",
    "        writer = csv.writer(f)\n",
    "        if os.stat(csv_file_path).st_size == 0:\n",
    "            # writer = csv.writer(f)\n",
    "            writer.writerow([\"REVIEW\", \"LABEL\", \"MODEL\", \"NUM_SHOTS\"])\n",
    "\n",
    "        print('Starting API call')\n",
    "\n",
    "        while True:\n",
    "            # try:\n",
    "            # Send request\n",
    "                # completion = openai.ChatCompletion.create(\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[{'role': 'system', 'content': system_content},\n",
    "                              {'role': 'user', 'content': fake_prompt}],\n",
    "                    temperature=temperature)\n",
    "\n",
    "                # Retrieve response\n",
    "                # response = completion['choices'][0]['message']['content']\n",
    "                response = completion.choices[0].message.content\n",
    "                # break  # Break out of the loop if API call is successful\n",
    "\n",
    "            #Handle errors\n",
    "            # except openai.error.APIError as e:\n",
    "            #     print(\"API error. Retrying... (if error persists, check status.openai.com)\")\n",
    "            #     time.sleep(10)\n",
    "            # except openai.error.Timeout as e:\n",
    "            #     print(\"Request timed out. Retrying... (if error persists, check internet connection)\")\n",
    "            #     time.sleep(5)\n",
    "            # except openai.error.RateLimitError as e:\n",
    "            #     print(\"Reached rate limit. Retrying... (if error persists, check number of tokens/requests)\")\n",
    "            #     time.sleep(60)\n",
    "            # except openai.error.APIConnectionError as e:\n",
    "            #     print(\"API connection error. Retrying... (if error persists, check network/proxy config/ssl/firewall)\")\n",
    "            #     time.sleep(5)\n",
    "            # except openai.error.InvalidRequestError as e:\n",
    "            #     print(\"Invalid request error. Retrying... (if error persists, check for invalid/missing request parameters)\")\n",
    "            # except openai.error.AuthenticationError as e:\n",
    "            #     print(\"Authentication error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "            # except openai.error.ServiceUnavailableError as e:\n",
    "            #     print(\"Server is overloaded. Retrying... (if error persists, check status.openai.com)\")\n",
    "            #     time.sleep(120)\n",
    "\n",
    "\n",
    "            # except APIException as e:\n",
    "            #     print(f\"APIRemovedInV1 error: {e}\")\n",
    "            # except client.error.APIError as e:\n",
    "            #     print(\"API error. Retrying... (if error persists, check status.openai.com)\")\n",
    "            #     time.sleep(10)\n",
    "            # except client.error.Timeout as e:\n",
    "            #     print(\"Request timed out. Retrying... (if error persists, check internet connection)\")\n",
    "            #     time.sleep(5)\n",
    "            # except client.error.RateLimitError as e:\n",
    "            #     print(\"Reached rate limit. Retrying... (if error persists, check number of tokens/requests)\")\n",
    "            #     time.sleep(60)\n",
    "            # except client.error.APIConnectionError as e:\n",
    "            #     print(\"API connection error. Retrying... (if error persists, check network/proxy config/ssl/firewall)\")\n",
    "            #     time.sleep(5)\n",
    "            # except client.error.InvalidRequestError as e:\n",
    "            #     print(\"Invalid request error. Retrying... (if error persists, check for invalid/missing request parameters)\")\n",
    "            # except client.error.AuthenticationError as e:\n",
    "            #     print(\"Authentication error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "            # except client.error.ServiceUnavailableError as e:\n",
    "            #     print(\"Server is overloaded. Retrying... (if error persists, check status.openai.com)\")\n",
    "            #     time.sleep(120)\n",
    "\n",
    "        # Write csv file\n",
    "        writer.writerow([response, \"FAKE\", model, shots])\n",
    "        print(f'Progress: {round(fake_review_count/len(dataset),2)*100}%')\n",
    "        fake_review_count +=1\n",
    "\n",
    "        f.close()\n",
    "    \n",
    "    return print(\"API calls complete\")\n",
    "\n",
    "# def make_api_calls(model: str, \n",
    "#                   system_content: str, \n",
    "#                   temperature: float, \n",
    "#                   num_shots: int,\n",
    "#                   dataset: pd.DataFrame\n",
    "#                   ):\n",
    "#     \"\"\"\n",
    "#     Make calls to ChatGPT's API using a specific prompt, model and temperature.\n",
    "\n",
    "#     Inputs:\n",
    "#         - model (str): model of OpenAI to use\n",
    "#         - system_content (str): content of system role\n",
    "#         - temperature (float): level of randomness of output\n",
    "#         - prompt (str): prompt to feed to the model\n",
    "#         - num_shots (int): number of examples in prompt\n",
    "    \n",
    "#     Returns a csv file where each row contains the statement and the output.\n",
    "#     \"\"\"\n",
    "\n",
    "#     fake_review_count = 0\n",
    "\n",
    "#     if num_shots == 0:\n",
    "#         shots = 'zero'\n",
    "#     else:\n",
    "#         shots = 'few'\n",
    "\n",
    "#     attr_moments = find_moments_of_attribute_distribution(dataset)\n",
    "#     attr_fake = create_fake_review_attributes(dataset, attr_moments)\n",
    "#     fake_prompt = generate_fake_review_prompt(dataset, base_prompt, num_shots, attr_fake)\n",
    "\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     csv_file_path = os.path.join(output_dir, f'fake_reviews_{model}_{num_shots}_shots.csv')\n",
    "\n",
    "#     with open(csv_file_path, mode='w', newline='') as f:\n",
    "\n",
    "#         # Create headers only if the file is empty\n",
    "#         if os.stat(csv_file_path).st_size == 0:\n",
    "#             writer = csv.writer(f)\n",
    "#             writer.writerow([\"REVIEW\", \"LABEL\", \"MODEL\", \"NUM_SHOTS\"])\n",
    "\n",
    "#         print('Starting API call')\n",
    "\n",
    "#         # API call\n",
    "#         while True:\n",
    "#             try:\n",
    "#             # Send request\n",
    "#                 completion = openai.ChatCompletion.create(\n",
    "#             # completion = client.chat.completions.create(\n",
    "#                 model=model,\n",
    "#                 messages=[{'role': 'system', 'content': system_content,\n",
    "#                         'role': 'user', 'content': fake_prompt}],\n",
    "#                 temperature=temperature)\n",
    "\n",
    "#                 # Retrieve response\n",
    "#                 response = completion['choices'][0]['message']['content']\n",
    "#                 break  # Break out of the loop if API call is successful\n",
    "\n",
    "#             #Handle errors\n",
    "#             # except:\n",
    "#             #     print(\"API error, trying again\")\n",
    "#             #     time.sleep(10)\n",
    "\n",
    "#             except openai.error.APIError as e:\n",
    "#                 print(\"API error. Retrying... (if error persists, check status.openai.com)\")\n",
    "#                 time.sleep(10)\n",
    "#             except openai.error.Timeout as e:\n",
    "#                 print(\"Request timed out. Retrying... (if error persists, check internet connection)\")\n",
    "#                 time.sleep(5)\n",
    "#             except openai.error.RateLimitError as e:\n",
    "#                 print(\"Reached rate limit. Retrying... (if error persists, check number of tokens/requests)\")\n",
    "#                 time.sleep(60)\n",
    "#             except openai.error.APIConnectionError as e:\n",
    "#                 print(\"API connection error. Retrying... (if error persists, check network/proxy config/ssl/firewall)\")\n",
    "#                 time.sleep(5)\n",
    "#             except openai.error.InvalidRequestError as e:\n",
    "#                 print(\"Invalid request error. Retrying... (if error persists, check for invalid/missing request parameters)\")\n",
    "#             except openai.error.AuthenticationError as e:\n",
    "#                 print(\"Authentication error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             except openai.error.ServiceUnavailableError as e:\n",
    "#                 print(\"Server is overloaded. Retrying... (if error persists, check status.openai.com)\")\n",
    "#                 time.sleep(120)\n",
    "\n",
    "#             #Handle errors\n",
    "#             # except:\n",
    "#             #     print(\"API error, trying again\")\n",
    "\n",
    "#             # except OpenAI.error.APIConnectionError as e:\n",
    "#             #     print(\"API connection error. Retrying... (if error persists, check network/proxy config/ssl/firewall)\")\n",
    "#             #     time.sleep(5)\n",
    "#             # except OpenAI.error.TimeoutError as e:\n",
    "#             #     print(\"Request timed out. Retrying... (if error persists, check internet connection)\")\n",
    "#             #     time.sleep(5)\n",
    "#             # except OpenAI.error.AuthenticationError as e:\n",
    "#             #     print(\"Authentication error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.BadRequestError as e:\n",
    "#             #     print(\"Bad request error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.ConflictError as e:\n",
    "#             #     print(\"Conflict error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.InternalServerError as e:\n",
    "#             #     print(\"Internal server error error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.NotFoundError as e:\n",
    "#             #     print(\"Not found error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.PermissionDeniedError as e:\n",
    "#             #     print(\"Permission denied error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.RateLimitError as e:\n",
    "#             #     print(\"Reached rate limit. Retrying... (if error persists, check number of tokens/requests)\")\n",
    "#             #     time.sleep(60)\n",
    "#             # except OpenAI.UnprocessableEntityError as e:\n",
    "#             #     print(\"Unprocessable entity error. Retrying... (if error persists, check for invalid/missing request parameters)\")\n",
    "\n",
    "#         # Write csv file\n",
    "#         writer.writerow([response, \"FAKE\", model, shots])\n",
    "#         print(f'Progress: {round(fake_review_count/len(dataset),2)*100}%')\n",
    "#         fake_review_count +=1\n",
    "\n",
    "#     f.close()\n",
    "    \n",
    "#     return print(\"API calls complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>comment_year</th>\n",
       "      <th>business_name</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UlPCp6kFGGUSKycc5kNiJg</td>\n",
       "      <td>PSA: CASH ONLY!! \\n\\nA hole in the wall family...</td>\n",
       "      <td>2019-11-13 14:25:16</td>\n",
       "      <td>d48Xrx8MhGtdaLvhcYzNWQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019,20,20,2021</td>\n",
       "      <td>2019</td>\n",
       "      <td>Cafe Diem</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2ZKf-CjGthLamYKNAcbJw</td>\n",
       "      <td>When you're craving empanadas, check out this ...</td>\n",
       "      <td>2019-11-09 19:40:02</td>\n",
       "      <td>ngU4740twiB222g4ti0_eQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019,20,20,2021</td>\n",
       "      <td>2019</td>\n",
       "      <td>Cocina Latina</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9fOezqmM4pYOHCcPD1C0aA</td>\n",
       "      <td>Loved our cheesesteaks. By the length of the l...</td>\n",
       "      <td>2019-12-03 17:15:01</td>\n",
       "      <td>8xTHtLoNIwdpf0FEvIpQIw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015,2016,2017,2018,2019,20,20,2021</td>\n",
       "      <td>2019</td>\n",
       "      <td>By George! Pizza Pasta &amp; Cheesesteaks</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UHuNFy-CDLj_SVMOQBHryw</td>\n",
       "      <td>Such fun! Great experience. Chef was terrific....</td>\n",
       "      <td>2021-09-25 14:35:27</td>\n",
       "      <td>29sZgoR7VN_3ck3NF5easg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20,20,2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>Izakaya Japanese Bar &amp; Grill</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DbiZXAui0L2LGHB5E0blrw</td>\n",
       "      <td>Really cool spot in Northern Liberties. Weathe...</td>\n",
       "      <td>2018-08-24 16:36:13</td>\n",
       "      <td>JUlsvVAvZvGHWFfkKm0nlg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018,2019</td>\n",
       "      <td>2018</td>\n",
       "      <td>El Camino Real</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id                                               text  \\\n",
       "0  UlPCp6kFGGUSKycc5kNiJg  PSA: CASH ONLY!! \\n\\nA hole in the wall family...   \n",
       "1  t2ZKf-CjGthLamYKNAcbJw  When you're craving empanadas, check out this ...   \n",
       "2  9fOezqmM4pYOHCcPD1C0aA  Loved our cheesesteaks. By the length of the l...   \n",
       "3  UHuNFy-CDLj_SVMOQBHryw  Such fun! Great experience. Chef was terrific....   \n",
       "4  DbiZXAui0L2LGHB5E0blrw  Really cool spot in Northern Liberties. Weathe...   \n",
       "\n",
       "                  date             business_id  stars  useful  funny  cool  \\\n",
       "0  2019-11-13 14:25:16  d48Xrx8MhGtdaLvhcYzNWQ    5.0       0      0     0   \n",
       "1  2019-11-09 19:40:02  ngU4740twiB222g4ti0_eQ    5.0       0      0     0   \n",
       "2  2019-12-03 17:15:01  8xTHtLoNIwdpf0FEvIpQIw    5.0       0      0     0   \n",
       "3  2021-09-25 14:35:27  29sZgoR7VN_3ck3NF5easg    5.0       0      0     0   \n",
       "4  2018-08-24 16:36:13  JUlsvVAvZvGHWFfkKm0nlg    5.0       0      0     0   \n",
       "\n",
       "                                 elite  comment_year  \\\n",
       "0                      2019,20,20,2021          2019   \n",
       "1                      2019,20,20,2021          2019   \n",
       "2  2015,2016,2017,2018,2019,20,20,2021          2019   \n",
       "3                           20,20,2021          2021   \n",
       "4                            2018,2019          2018   \n",
       "\n",
       "                           business_name  text_length  \n",
       "0                              Cafe Diem          622  \n",
       "1                          Cocina Latina          235  \n",
       "2  By George! Pizza Pasta & Cheesesteaks          261  \n",
       "3           Izakaya Japanese Bar & Grill          265  \n",
       "4                         El Camino Real          975  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "data = pd.read_csv('data/yelp/yelp_verified_slim.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11106"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attr_moments = find_moments_of_attribute_distribution(data)\n",
    "# attr_fake = create_fake_review_attributes(data, attr_moments)\n",
    "# print(attr_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_shots=3\n",
    "# reviews = draw_reviews_from_verified_sample(data, num_shots, attr_fake)\n",
    "# for r in reviews:\n",
    "#     print(r)\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You attended a restaurant named Starbucks.\n",
      "You rated your experience with 5 stars out of 5.\n",
      "Write a review of 2108 characters describing your experience.\n",
      "\n",
      "Consider the examples below:\n",
      "\n",
      "##\n",
      "Example 1: Restaurant name = Starbucks; Number of characters = 4; Number of stars = 4.0.\n",
      "Review 1: I go into this Starbucks when stopping into Macy's.  I agree with other reviewers that the baristas are friendly, the lines are typically short and move quickly, however my main complaint with this Starbucks is that the music is usually so loud, much louder than other coffee shops, it makes it hard to relax.  They usually play something so upbeat, it would be nicer if it was something more laidback.  \n",
      "\n",
      "There is plenty of seating available, however it gets crowded quickly, I think from the people coming from Macy's and the shoppers coming from other Chestnut St stores.\n",
      "\n",
      "For me, this Starbucks is good in a pinch, but it's not my usual hangout....\n",
      "####\n",
      "Example 2: Restaurant name = Starbucks; Number of characters = 4; Number of stars = 4.0.\n",
      "Review 2: Exiting Crate & Barrell, I needed a pick me up to continue on my day in Tampa and decided to stroll in. Everyone is always so friendly here & my order was taken with a smile and was prepared quickly. They have a drive through for those who are on the run and still deserve their caffeine oomph. The entrance is a bit weird because it's a double lane that cuts off into a weird yielding turn so if there's traffic, you can be stuck on either side for a while. The WiFi is always strong and since the coffee shop is very clean- it allows for a laptop session alongside your iced coffee. There's a hunch if outlets everywhere which is probably due to them being a newer and more renovated location. Starbucks is always a good idea so when you're in the area, stop by for a quick caffeine boost. You'll be glad you did!.\n",
      "####\n",
      "Example 3: Restaurant name = Starbucks; Number of characters = 4; Number of stars = 1.0.\n",
      "Review 3: -2stars. Now that's generous. \n",
      "\n",
      "Please keep reading to find out why.\n",
      "\n",
      "The staff at this Hyatt Hotel location Starbucks deserves to be informed about coffee. I have had opportunities to visit Italy and experience real coffee, espresso and cappuccinos.  Attitude of cashier at this location made me think that the Italians got it wrong. The attitude, the arrogance and refusal to correct their thinking puzzled me the most. And according to this cashier on duty, the Italians have it wrong since the 17th century. I was so puzzled that I chose to look up definition of cappuccino before writing this. It was an indeed a very disappointing and humiliating experience at this Hyatt location next to the Arch at STL..\n",
      "##\n"
     ]
    }
   ],
   "source": [
    "num_shots=3\n",
    "attr_moments = find_moments_of_attribute_distribution(data)\n",
    "attr_fake = create_fake_review_attributes(data, attr_moments)\n",
    "fake_prompt = generate_fake_review_prompt(data, base_prompt, num_shots, attr_fake)\n",
    "print(fake_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test."
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting API call\n",
      "Progress: 0.0%\n",
      "API calls complete\n"
     ]
    }
   ],
   "source": [
    "make_api_calls(model='gpt-3.5-turbo-16k-0613', \n",
    "               system_content='You are a person that writes restaurant reviews', \n",
    "               temperature=1.0, \n",
    "               num_shots=0,\n",
    "               dataset= pd.read_csv('data/yelp/yelp_verified_slim.csv')\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting API call\n",
      "Progress: 0.0%\n",
      "API calls complete\n",
      "Starting API call\n",
      "Progress: 0.0%\n",
      "API calls complete\n",
      "Starting API call\n",
      "Progress: 0.0%\n",
      "API calls complete\n"
     ]
    }
   ],
   "source": [
    "#Split dataset for API calls\n",
    "part_size = len(data) // 3\n",
    "\n",
    "#Jack\n",
    "make_api_calls(model='gpt-4-1106-preview', \n",
    "               system_content='You are a person that writes restaurant reviews', \n",
    "               temperature=1.0, \n",
    "               num_shots=3,\n",
    "               dataset= data.iloc[:part_size]\n",
    "               )\n",
    "\n",
    "#Claire\n",
    "make_api_calls(model='gpt-3.5-turbo-16k-0613', \n",
    "               system_content='You are a person that writes restaurant reviews', \n",
    "               temperature=1.0, \n",
    "               num_shots=3,\n",
    "               dataset= data.iloc[part_size:2 * part_size]\n",
    "               )\n",
    "\n",
    "#Benja\n",
    "make_api_calls(model='gpt-3.5-turbo-16k-0613', \n",
    "               system_content='You are a person that writes restaurant reviews', \n",
    "               temperature=1.0, \n",
    "               num_shots=0,\n",
    "               dataset= data.iloc[part_size:2 * part_size]\n",
    "               )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
