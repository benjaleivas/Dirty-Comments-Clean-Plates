{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Reviews\n",
    "\n",
    "This Jupyter Notebook creates fake reviews using ChatGPT, using different models (GPT-3.5, GPT-4), prompt engineering techniques (zero- vs few-shot prompts), restaurant and review characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base prompt:\n",
      "\n",
      "You attended a restaurant named REST_NAME.\n",
      "You rated your experience with NUM_STARS stars out of 5.\n",
      "Write a review of NUM_CHAR characters describing your experience.\n"
     ]
    }
   ],
   "source": [
    "#Dependencies\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "# from openai import openai, APIRemovedInV1\n",
    "# import openai # pip install openai==0.27.8\n",
    "\n",
    "#Directories\n",
    "os.chdir('/home/bleiva/capp30255/how_the_bear_got_a_C')\n",
    "output_dir = 'how_the_bear_got_a_C/chat_gpt'\n",
    "\n",
    "#OpenAI\n",
    "client = OpenAI()\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
    "\n",
    "#Base prompt\n",
    "with open('chat_gpt/base_prompt.txt', 'r') as file:\n",
    "    base_prompt = file.read()\n",
    "\n",
    "print(f'Base prompt:\\n\\n{base_prompt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_moments_of_attribute_distribution(dataset: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Finds review attributes from underlying distributions of real reviews.\n",
    "\n",
    "    Input:\n",
    "        - dataset (DataFrame): a pandas dataframe.\n",
    "    \n",
    "    Returns dictionary with attribute (str), moments (dict) pairs. \n",
    "    \"\"\"\n",
    "\n",
    "    #Create output structure\n",
    "    attr_moments = {'stars': None, 'text_length': None}\n",
    "\n",
    "    #Compute moments for rest of attributes\n",
    "    for attr in ['stars', 'text_length']:\n",
    "        attr_moments[attr] = {'mean': dataset[attr].mean(),\n",
    "                             'median': dataset[attr].median(), \n",
    "                             'std': dataset[attr].std()}\n",
    "\n",
    "    return attr_moments\n",
    "\n",
    "def create_fake_review_attributes(dataset: pd.DataFrame, attr_moments: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Creates attributes by drawing random value from empirical distribution.\n",
    "\n",
    "    Input:\n",
    "        - attribute_moments (dict): a dictionary of attribute, moments.\n",
    "    \n",
    "    Returns dictionary where each key, value is an attribute, value.\n",
    "    \"\"\"\n",
    "\n",
    "    #Create output structure\n",
    "    attrs = {'business_name': None, 'stars': None, 'text_length': None}\n",
    "\n",
    "    #Compute and store values\n",
    "    for key in ['text_length', 'stars', 'business_name']:\n",
    "        if key == 'text_length':\n",
    "            attr_value = round(abs(np.random.normal(attr_moments[key]['mean'], attr_moments[key]['std'])))\n",
    "            # print('picked_text_length:', attr_value)\n",
    "        elif key == 'stars':\n",
    "            choices = [1, 2, 3, 4, 5]\n",
    "            probs = [0.153, 0.078, 0.099, 0.208, 0.462] #from empirical distribution\n",
    "            attr_value = np.random.choice(choices, p=probs)\n",
    "            # print('picked_star:', attr_value)\n",
    "        elif key == 'business_name':\n",
    "            attr_value = np.random.choice(dataset[key])\n",
    "            # print('picked_name:', attr_value)\n",
    "        #Store in dictionary\n",
    "        attrs[key] = attr_value\n",
    "\n",
    "    return attrs\n",
    "\n",
    "def draw_reviews_from_verified_sample(dataset: pd.DataFrame, \n",
    "                                      num_draws: int, \n",
    "                                      attributes: dict) -> list:\n",
    "    \"\"\"\n",
    "    Takes a set of attributes and randomly draws verified reviews with those \n",
    "    characteristics.\n",
    "\n",
    "    Inputs:\n",
    "        - dataset (DataFrame): a pandas dataframe\n",
    "        - num_draws (int): number of reviews to extract from dataset\n",
    "        - attributes (dict): key, value pairs of attributes to filter from\n",
    "\n",
    "    Returns a list of reviews that match those attributes.        \n",
    "    \"\"\"\n",
    "\n",
    "    #Filter dataset\n",
    "    filtered_dataset = dataset[dataset['business_name'] == attributes['business_name']]\n",
    "    num_rows = filtered_dataset.shape[0]\n",
    "\n",
    "    #Pick reviews\n",
    "    if num_rows >= num_draws:\n",
    "        sampled_rows = filtered_dataset.sample(n=num_draws, replace=False)\n",
    "    else:\n",
    "        sampled_rows = filtered_dataset.sample(n=num_rows, replace=False)\n",
    "\n",
    "    examples = []\n",
    "    for _, row in sampled_rows.iterrows():\n",
    "        d = {'business_name': row['business_name'], 'stars': row['stars'], 'text_length': row['text_length'], 'text': row['text']}\n",
    "        examples.append(d)\n",
    "\n",
    "    return examples\n",
    "\n",
    "def generate_fake_review_prompt(dataset: pd.DataFrame,\n",
    "                                base_prompt: str,\n",
    "                                num_shots: int,\n",
    "                                attributes: dict) -> str:\n",
    "    \"\"\"\n",
    "    Takes review characteristics and outputs a fake review.\n",
    "    \n",
    "    Inputs:\n",
    "        - base_prompt (str): standard prompt to build from\n",
    "        - num_shots (int): number of examples to give in prompt\n",
    "        - review_length (int): max number of words contained in review\n",
    "        - restaurant (str): name of the restaurant that is getting reviewed\n",
    "        - num_stars (int): rating of the restaurant by the (fake) user\n",
    "        - useful (boolean): True if review is useful, False otherwise \n",
    "        - funny (boolean): True if review is funny, False otherwise\n",
    "        - cool (boolean):  True if review is cool, False otherwise  \n",
    "\n",
    "    Returns a prompt to generate fake review in ChatGPT's API.\n",
    "    \"\"\"\n",
    "\n",
    "    #Build prompt based on relevant variables\n",
    "    prompt = base_prompt.replace(\"REST_NAME\", attributes['business_name']) \\\n",
    "                        .replace(\"NUM_CHAR\", str(abs(attributes['text_length']))) \\\n",
    "                        .replace(\"NUM_STARS\", str(attributes['stars']))\n",
    "    #Zero-shot\n",
    "    if num_shots == 0:\n",
    "        return prompt\n",
    "    \n",
    "    #Few-shot\n",
    "    reviews = draw_reviews_from_verified_sample(dataset, num_shots, attributes)\n",
    "    few_shot_text = '\\n\\nConsider the examples below:\\n\\n'\n",
    "    count = 1\n",
    "    for i in range(len(reviews)):\n",
    "        few_shot_text += f\"##\\nExample {count}: Restaurant name = {reviews[i]['business_name']}; \" \\\n",
    "                        f\"Number of characters = {str(len(reviews[i]))}; \" \\\n",
    "                        f\"Number of stars = {str(reviews[i]['stars'])}.\\n\" \\\n",
    "                        f\"Review {count}: {reviews[i]['text']}.\\n##\"\n",
    "        count +=1\n",
    "\n",
    "    prompt = prompt+few_shot_text\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def make_api_calls(model: str, \n",
    "                  system_content: str, \n",
    "                  temperature: float, \n",
    "                  num_shots: int,\n",
    "                  dataset: pd.DataFrame\n",
    "                  ):\n",
    "    \"\"\"\n",
    "    Make calls to ChatGPT's API using a specific prompt, model, and temperature.\n",
    "\n",
    "    Inputs:\n",
    "        - model (str): model of OpenAI to use\n",
    "        - system_content (str): content of system role\n",
    "        - temperature (float): level of randomness of output\n",
    "        - num_shots (int): number of examples in prompt\n",
    "        - dataset (pd.DataFrame): DataFrame containing the dataset\n",
    "    \n",
    "    Returns a csv file where each row contains the statement and the output.\n",
    "    \"\"\"\n",
    "\n",
    "    fake_review_count = 0\n",
    "\n",
    "    if num_shots == 0:\n",
    "        shots = 'zero'\n",
    "    else:\n",
    "        shots = 'few'\n",
    "\n",
    "    attr_moments = find_moments_of_attribute_distribution(dataset)\n",
    "    attr_fake = create_fake_review_attributes(dataset, attr_moments)\n",
    "    fake_prompt = generate_fake_review_prompt(dataset, base_prompt, num_shots, attr_fake)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    csv_file_path = os.path.join(output_dir, f'fake_reviews_{model}_{num_shots}_shots.csv')\n",
    "\n",
    "    with open(csv_file_path, mode='w', newline='') as f:\n",
    "\n",
    "        # Create headers only if the file is empty\n",
    "        if os.stat(csv_file_path).st_size == 0:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"REVIEW\", \"LABEL\", \"MODEL\", \"NUM_SHOTS\"])\n",
    "\n",
    "        print('Starting API call')\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "            # Send request\n",
    "                # completion = openai.ChatCompletion.create(\n",
    "                completion = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{'role': 'system', 'content': system_content,\n",
    "                        'role': 'user', 'content': fake_prompt}],\n",
    "                temperature=temperature)\n",
    "\n",
    "                # Retrieve response\n",
    "                response = completion['choices'][0]['message']['content']\n",
    "                break  # Break out of the loop if API call is successful\n",
    "\n",
    "            except APIException as e:\n",
    "                print(f\"APIRemovedInV1 error: {e}\")\n",
    "            # except client.error.APIError as e:\n",
    "            #     print(\"API error. Retrying... (if error persists, check status.openai.com)\")\n",
    "            #     time.sleep(10)\n",
    "            # except client.error.Timeout as e:\n",
    "            #     print(\"Request timed out. Retrying... (if error persists, check internet connection)\")\n",
    "            #     time.sleep(5)\n",
    "            # except client.error.RateLimitError as e:\n",
    "            #     print(\"Reached rate limit. Retrying... (if error persists, check number of tokens/requests)\")\n",
    "            #     time.sleep(60)\n",
    "            # except client.error.APIConnectionError as e:\n",
    "            #     print(\"API connection error. Retrying... (if error persists, check network/proxy config/ssl/firewall)\")\n",
    "            #     time.sleep(5)\n",
    "            # except client.error.InvalidRequestError as e:\n",
    "            #     print(\"Invalid request error. Retrying... (if error persists, check for invalid/missing request parameters)\")\n",
    "            # except client.error.AuthenticationError as e:\n",
    "            #     print(\"Authentication error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "            # except client.error.ServiceUnavailableError as e:\n",
    "            #     print(\"Server is overloaded. Retrying... (if error persists, check status.openai.com)\")\n",
    "            #     time.sleep(120)\n",
    "\n",
    "        # Write csv file\n",
    "        writer.writerow([response, \"FAKE\", model, shots])\n",
    "        print(f'Progress: {round(fake_review_count/len(dataset),2)*100}%')\n",
    "        fake_review_count +=1\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    return print(\"API calls complete\")\n",
    "\n",
    "# def make_api_calls(model: str, \n",
    "#                   system_content: str, \n",
    "#                   temperature: float, \n",
    "#                   num_shots: int,\n",
    "#                   dataset: pd.DataFrame\n",
    "#                   ):\n",
    "#     \"\"\"\n",
    "#     Make calls to ChatGPT's API using a specific prompt, model and temperature.\n",
    "\n",
    "#     Inputs:\n",
    "#         - model (str): model of OpenAI to use\n",
    "#         - system_content (str): content of system role\n",
    "#         - temperature (float): level of randomness of output\n",
    "#         - prompt (str): prompt to feed to the model\n",
    "#         - num_shots (int): number of examples in prompt\n",
    "    \n",
    "#     Returns a csv file where each row contains the statement and the output.\n",
    "#     \"\"\"\n",
    "\n",
    "#     fake_review_count = 0\n",
    "\n",
    "#     if num_shots == 0:\n",
    "#         shots = 'zero'\n",
    "#     else:\n",
    "#         shots = 'few'\n",
    "\n",
    "#     attr_moments = find_moments_of_attribute_distribution(dataset)\n",
    "#     attr_fake = create_fake_review_attributes(dataset, attr_moments)\n",
    "#     fake_prompt = generate_fake_review_prompt(dataset, base_prompt, num_shots, attr_fake)\n",
    "\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     csv_file_path = os.path.join(output_dir, f'fake_reviews_{model}_{num_shots}_shots.csv')\n",
    "\n",
    "#     with open(csv_file_path, mode='w', newline='') as f:\n",
    "\n",
    "#         # Create headers only if the file is empty\n",
    "#         if os.stat(csv_file_path).st_size == 0:\n",
    "#             writer = csv.writer(f)\n",
    "#             writer.writerow([\"REVIEW\", \"LABEL\", \"MODEL\", \"NUM_SHOTS\"])\n",
    "\n",
    "#         print('Starting API call')\n",
    "\n",
    "#         # API call\n",
    "#         while True:\n",
    "#             try:\n",
    "#             # Send request\n",
    "#                 completion = openai.ChatCompletion.create(\n",
    "#             # completion = client.chat.completions.create(\n",
    "#                 model=model,\n",
    "#                 messages=[{'role': 'system', 'content': system_content,\n",
    "#                         'role': 'user', 'content': fake_prompt}],\n",
    "#                 temperature=temperature)\n",
    "\n",
    "#                 # Retrieve response\n",
    "#                 response = completion['choices'][0]['message']['content']\n",
    "#                 break  # Break out of the loop if API call is successful\n",
    "\n",
    "#             #Handle errors\n",
    "#             # except:\n",
    "#             #     print(\"API error, trying again\")\n",
    "#             #     time.sleep(10)\n",
    "\n",
    "#             except openai.error.APIError as e:\n",
    "#                 print(\"API error. Retrying... (if error persists, check status.openai.com)\")\n",
    "#                 time.sleep(10)\n",
    "#             except openai.error.Timeout as e:\n",
    "#                 print(\"Request timed out. Retrying... (if error persists, check internet connection)\")\n",
    "#                 time.sleep(5)\n",
    "#             except openai.error.RateLimitError as e:\n",
    "#                 print(\"Reached rate limit. Retrying... (if error persists, check number of tokens/requests)\")\n",
    "#                 time.sleep(60)\n",
    "#             except openai.error.APIConnectionError as e:\n",
    "#                 print(\"API connection error. Retrying... (if error persists, check network/proxy config/ssl/firewall)\")\n",
    "#                 time.sleep(5)\n",
    "#             except openai.error.InvalidRequestError as e:\n",
    "#                 print(\"Invalid request error. Retrying... (if error persists, check for invalid/missing request parameters)\")\n",
    "#             except openai.error.AuthenticationError as e:\n",
    "#                 print(\"Authentication error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             except openai.error.ServiceUnavailableError as e:\n",
    "#                 print(\"Server is overloaded. Retrying... (if error persists, check status.openai.com)\")\n",
    "#                 time.sleep(120)\n",
    "\n",
    "#             #Handle errors\n",
    "#             # except:\n",
    "#             #     print(\"API error, trying again\")\n",
    "\n",
    "#             # except OpenAI.error.APIConnectionError as e:\n",
    "#             #     print(\"API connection error. Retrying... (if error persists, check network/proxy config/ssl/firewall)\")\n",
    "#             #     time.sleep(5)\n",
    "#             # except OpenAI.error.TimeoutError as e:\n",
    "#             #     print(\"Request timed out. Retrying... (if error persists, check internet connection)\")\n",
    "#             #     time.sleep(5)\n",
    "#             # except OpenAI.error.AuthenticationError as e:\n",
    "#             #     print(\"Authentication error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.BadRequestError as e:\n",
    "#             #     print(\"Bad request error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.ConflictError as e:\n",
    "#             #     print(\"Conflict error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.InternalServerError as e:\n",
    "#             #     print(\"Internal server error error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.NotFoundError as e:\n",
    "#             #     print(\"Not found error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.PermissionDeniedError as e:\n",
    "#             #     print(\"Permission denied error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.RateLimitError as e:\n",
    "#             #     print(\"Reached rate limit. Retrying... (if error persists, check number of tokens/requests)\")\n",
    "#             #     time.sleep(60)\n",
    "#             # except OpenAI.UnprocessableEntityError as e:\n",
    "#             #     print(\"Unprocessable entity error. Retrying... (if error persists, check for invalid/missing request parameters)\")\n",
    "\n",
    "#         # Write csv file\n",
    "#         writer.writerow([response, \"FAKE\", model, shots])\n",
    "#         print(f'Progress: {round(fake_review_count/len(dataset),2)*100}%')\n",
    "#         fake_review_count +=1\n",
    "\n",
    "#     f.close()\n",
    "    \n",
    "#     return print(\"API calls complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>comment_year</th>\n",
       "      <th>business_name</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UlPCp6kFGGUSKycc5kNiJg</td>\n",
       "      <td>PSA: CASH ONLY!! \\n\\nA hole in the wall family...</td>\n",
       "      <td>2019-11-13 14:25:16</td>\n",
       "      <td>d48Xrx8MhGtdaLvhcYzNWQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019,20,20,2021</td>\n",
       "      <td>2019</td>\n",
       "      <td>Cafe Diem</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2ZKf-CjGthLamYKNAcbJw</td>\n",
       "      <td>When you're craving empanadas, check out this ...</td>\n",
       "      <td>2019-11-09 19:40:02</td>\n",
       "      <td>ngU4740twiB222g4ti0_eQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019,20,20,2021</td>\n",
       "      <td>2019</td>\n",
       "      <td>Cocina Latina</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9fOezqmM4pYOHCcPD1C0aA</td>\n",
       "      <td>Loved our cheesesteaks. By the length of the l...</td>\n",
       "      <td>2019-12-03 17:15:01</td>\n",
       "      <td>8xTHtLoNIwdpf0FEvIpQIw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015,2016,2017,2018,2019,20,20,2021</td>\n",
       "      <td>2019</td>\n",
       "      <td>By George! Pizza Pasta &amp; Cheesesteaks</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UHuNFy-CDLj_SVMOQBHryw</td>\n",
       "      <td>Such fun! Great experience. Chef was terrific....</td>\n",
       "      <td>2021-09-25 14:35:27</td>\n",
       "      <td>29sZgoR7VN_3ck3NF5easg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20,20,2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>Izakaya Japanese Bar &amp; Grill</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DbiZXAui0L2LGHB5E0blrw</td>\n",
       "      <td>Really cool spot in Northern Liberties. Weathe...</td>\n",
       "      <td>2018-08-24 16:36:13</td>\n",
       "      <td>JUlsvVAvZvGHWFfkKm0nlg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018,2019</td>\n",
       "      <td>2018</td>\n",
       "      <td>El Camino Real</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id                                               text  \\\n",
       "0  UlPCp6kFGGUSKycc5kNiJg  PSA: CASH ONLY!! \\n\\nA hole in the wall family...   \n",
       "1  t2ZKf-CjGthLamYKNAcbJw  When you're craving empanadas, check out this ...   \n",
       "2  9fOezqmM4pYOHCcPD1C0aA  Loved our cheesesteaks. By the length of the l...   \n",
       "3  UHuNFy-CDLj_SVMOQBHryw  Such fun! Great experience. Chef was terrific....   \n",
       "4  DbiZXAui0L2LGHB5E0blrw  Really cool spot in Northern Liberties. Weathe...   \n",
       "\n",
       "                  date             business_id  stars  useful  funny  cool  \\\n",
       "0  2019-11-13 14:25:16  d48Xrx8MhGtdaLvhcYzNWQ    5.0       0      0     0   \n",
       "1  2019-11-09 19:40:02  ngU4740twiB222g4ti0_eQ    5.0       0      0     0   \n",
       "2  2019-12-03 17:15:01  8xTHtLoNIwdpf0FEvIpQIw    5.0       0      0     0   \n",
       "3  2021-09-25 14:35:27  29sZgoR7VN_3ck3NF5easg    5.0       0      0     0   \n",
       "4  2018-08-24 16:36:13  JUlsvVAvZvGHWFfkKm0nlg    5.0       0      0     0   \n",
       "\n",
       "                                 elite  comment_year  \\\n",
       "0                      2019,20,20,2021          2019   \n",
       "1                      2019,20,20,2021          2019   \n",
       "2  2015,2016,2017,2018,2019,20,20,2021          2019   \n",
       "3                           20,20,2021          2021   \n",
       "4                            2018,2019          2018   \n",
       "\n",
       "                           business_name  text_length  \n",
       "0                              Cafe Diem          622  \n",
       "1                          Cocina Latina          235  \n",
       "2  By George! Pizza Pasta & Cheesesteaks          261  \n",
       "3           Izakaya Japanese Bar & Grill          265  \n",
       "4                         El Camino Real          975  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "data = pd.read_csv('data/yelp/yelp_verified_slim.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11106"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attr_moments = find_moments_of_attribute_distribution(data)\n",
    "# attr_fake = create_fake_review_attributes(data, attr_moments)\n",
    "# print(attr_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_shots=3\n",
    "# reviews = draw_reviews_from_verified_sample(data, num_shots, attr_fake)\n",
    "# for r in reviews:\n",
    "#     print(r)\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You attended a restaurant named Mi Nidito Restaurant.\n",
      "You rated your experience with 5 stars out of 5.\n",
      "Write a review of 137 characters describing your experience.\n",
      "\n",
      "Consider the examples below:\n",
      "\n",
      "##\n",
      "Example 1: Restaurant name = Mi Nidito Restaurant; Number of characters = 4; Number of stars = 2.0.\n",
      "Review 1: OK, been a while, but that is because I was not impressed.  The ambiance of the decor is about the best thing going for it.  I truly do not know why this place is constantly packed to the brim with folks.  Nor do I understand why anyone would wait an hour plus to be seated.  A restaurant would have to be absolutely incredible, plus have seating at a bar for me to wait that long.  Speaking of seating, there are two small benches for those waiting to be seated.  Don't expect to find a place to sit, in other words.  All that aside, it is about the food, right?  I mean, the place is packed.  Clinton liked it.  Willie Nelson liked it.  Other celebrities liked it.  SO it's got to be good, right?  Nope.  Mediocre at best.  And certainly not worth the wait.  Upon a recommendation from a friend, I left there last time I tried to get in and headed down the road a little to Las Cazuelitas (now at 22nd and Country Club, plus a couple other locations around town).  No wait to be seated.  Nice ambiance.  A bar.  Much, much better food, with a larger selection.  \n",
      "If you need to feel empowered by going where some celebrities have gone, then by all means, deal with the hour plus wait for fancy taco bell.  If you just want good Mexican, go almost anywhere else.  Or don't.  Then I can keep walking in to the places I frequent and get a seat right away..\n",
      "####\n",
      "Example 2: Restaurant name = Mi Nidito Restaurant; Number of characters = 4; Number of stars = 4.0.\n",
      "Review 2: I enjoyed my chicken enchiladas (the pulled chicken was moist and flavorful), the chips were crispy and the salsa was good.  Service was indeed friendly and the ambiance was perfect for the food.  Bathrooms were clean and when I'm back in Tucson will try again.  Wait time for food was longer than it should have been..\n",
      "####\n",
      "Example 3: Restaurant name = Mi Nidito Restaurant; Number of characters = 4; Number of stars = 4.0.\n",
      "Review 3: After I finally found them hidden on a side street I luckily only had to wait 5 or so minutes for a table.  Although the restaurant was crowded and busy the service was still good, if a little slow.  The restaurant is fairly small so the seating is pretty close together so this would probably not be the best place to be private or have a conversation that you don't want overheard.  I ordered the Green Chili Enchiladas and they were amazing.  Why do places in California not use green chili like they do in Arizona and New Mexico??  It is seriously delicious.  So anyhow, yes the enchiladas were tasty and cheesy and I wish I could eat about 100 of them.  This was my favorite meal I had while in Tucson..\n",
      "##\n"
     ]
    }
   ],
   "source": [
    "num_shots=3\n",
    "attr_moments = find_moments_of_attribute_distribution(data)\n",
    "attr_fake = create_fake_review_attributes(data, attr_moments)\n",
    "fake_prompt = generate_fake_review_prompt(data, base_prompt, num_shots, attr_fake)\n",
    "print(fake_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting API call\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'APIException' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 174\u001b[0m, in \u001b[0;36mmake_api_calls\u001b[0;34m(model, system_content, temperature, num_shots, dataset)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Send request\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# completion = openai.ChatCompletion.create(\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# Retrieve response\u001b[39;00m\n",
      "File \u001b[0;32m~/capp30255/advml/lib/python3.10/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/capp30255/advml/lib/python3.10/site-packages/openai/resources/chat/completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/capp30255/advml/lib/python3.10/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1197\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m )\n\u001b[0;32m-> 1200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/capp30255/advml/lib/python3.10/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/capp30255/advml/lib/python3.10/site-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    988\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: OPENAI_A**_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmake_api_calls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo-16k-0613\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[43msystem_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYou are a person that writes restaurant reviews\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m               \u001b[49m\u001b[43mnum_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/yelp/yelp_verified_slim.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[126], line 184\u001b[0m, in \u001b[0;36mmake_api_calls\u001b[0;34m(model, system_content, temperature, num_shots, dataset)\u001b[0m\n\u001b[1;32m    181\u001b[0m         response \u001b[38;5;241m=\u001b[39m completion[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Break out of the loop if API call is successful\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mAPIException\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPIRemovedInV1 error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# except client.error.APIError as e:\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m#     print(\"API error. Retrying... (if error persists, check status.openai.com)\")\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m#     time.sleep(10)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# Write csv file\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'APIException' is not defined"
     ]
    }
   ],
   "source": [
    "make_api_calls(model='gpt-3.5-turbo-16k-0613', \n",
    "               system_content='You are a person that writes restaurant reviews', \n",
    "               temperature=1.0, \n",
    "               num_shots=0,\n",
    "               dataset= pd.read_csv('data/yelp/yelp_verified_slim.csv')\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset for API calls\n",
    "part_size = len(data) // 3\n",
    "\n",
    "#Jack\n",
    "make_api_calls(model='gpt-4-1106-preview', \n",
    "               system_content='You are a person that writes restaurant reviews', \n",
    "               temperature=1.0, \n",
    "               num_shots=3,\n",
    "               dataset= data.iloc[:part_size]\n",
    "               )\n",
    "\n",
    "#Claire\n",
    "make_api_calls(model='gpt-3.5-turbo-16k-0613', \n",
    "               system_content='You are a person that writes restaurant reviews', \n",
    "               temperature=1.0, \n",
    "               num_shots=3,\n",
    "               dataset= data.iloc[part_size:2 * part_size]\n",
    "               )\n",
    "\n",
    "#Benja\n",
    "make_api_calls(model='gpt-3.5-turbo-16k-0613', \n",
    "               system_content='You are a person that writes restaurant reviews', \n",
    "               temperature=1.0, \n",
    "               num_shots=0,\n",
    "               dataset= data.iloc[part_size:2 * part_size]\n",
    "               )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
