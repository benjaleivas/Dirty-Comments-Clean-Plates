{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Reviews\n",
    "\n",
    "This Jupyter Notebook creates fake reviews using ChatGPT, using different models (GPT-3.5, GPT-4), prompt engineering techniques (zero- vs few-shot prompts), restaurant and review characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from openai) (2.6.3)\n",
      "Requirement already satisfied: sniffio in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base prompt:\n",
      "\n",
      "You attended a restaurant named REST_NAME.\n",
      "You rated your experience with NUM_STARS stars out of 5.\n",
      "Write a review of NUM_CHAR characters describing your experience.\n"
     ]
    }
   ],
   "source": [
    "#Dependencies\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "# from openai import openai, APIRemovedInV1\n",
    "# import openai # pip install openai==0.27.8\n",
    "\n",
    "#Directories\n",
    "os.chdir('/Users/jackgibson/Documents/advanced_ml/how_the_bear_got_a_C')\n",
    "output_dir = 'how_the_bear_got_a_C/chat_gpt'\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "\n",
    "#OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "#Base prompt\n",
    "with open('chat_gpt/base_prompt.txt', 'r') as file:\n",
    "    base_prompt = file.read()\n",
    "\n",
    "print(f'Base prompt:\\n\\n{base_prompt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_moments_of_attribute_distribution(dataset: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Finds review attributes from underlying distributions of real reviews.\n",
    "\n",
    "    Input:\n",
    "        - dataset (DataFrame): a pandas dataframe.\n",
    "    \n",
    "    Returns dictionary with attribute (str), moments (dict) pairs. \n",
    "    \"\"\"\n",
    "\n",
    "    #Create output structure\n",
    "    attr_moments = {'stars': None, 'text_length': None}\n",
    "\n",
    "    #Compute moments for rest of attributes\n",
    "    for attr in ['stars', 'text_length']:\n",
    "        attr_moments[attr] = {'mean': dataset[attr].mean(),\n",
    "                             'median': dataset[attr].median(), \n",
    "                             'std': dataset[attr].std()}\n",
    "\n",
    "    return attr_moments\n",
    "\n",
    "def create_fake_review_attributes(dataset: pd.DataFrame, attr_moments: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Creates attributes by drawing random value from empirical distribution.\n",
    "\n",
    "    Input:\n",
    "        - attribute_moments (dict): a dictionary of attribute, moments.\n",
    "    \n",
    "    Returns dictionary where each key, value is an attribute, value.\n",
    "    \"\"\"\n",
    "\n",
    "    #Create output structure\n",
    "    attrs = {'business_name': None, 'stars': None, 'text_length': None}\n",
    "\n",
    "    #Compute and store values\n",
    "    for key in ['text_length', 'stars', 'business_name']:\n",
    "        if key == 'text_length':\n",
    "            attr_value = round(abs(np.random.normal(attr_moments[key]['mean'], attr_moments[key]['std'])))\n",
    "            # print('picked_text_length:', attr_value)\n",
    "        elif key == 'stars':\n",
    "            choices = [1, 2, 3, 4, 5]\n",
    "            probs = [0.153, 0.078, 0.099, 0.208, 0.462] #from empirical distribution\n",
    "            attr_value = np.random.choice(choices, p=probs)\n",
    "            # print('picked_star:', attr_value)\n",
    "        elif key == 'business_name':\n",
    "            attr_value = np.random.choice(dataset[key])\n",
    "            # print('picked_name:', attr_value)\n",
    "        #Store in dictionary\n",
    "        attrs[key] = attr_value\n",
    "\n",
    "    return attrs\n",
    "\n",
    "def draw_reviews_from_verified_sample(dataset: pd.DataFrame, \n",
    "                                      num_draws: int, \n",
    "                                      attributes: dict) -> list:\n",
    "    \"\"\"\n",
    "    Takes a set of attributes and randomly draws verified reviews with those \n",
    "    characteristics.\n",
    "\n",
    "    Inputs:\n",
    "        - dataset (DataFrame): a pandas dataframe\n",
    "        - num_draws (int): number of reviews to extract from dataset\n",
    "        - attributes (dict): key, value pairs of attributes to filter from\n",
    "\n",
    "    Returns a list of reviews that match those attributes.        \n",
    "    \"\"\"\n",
    "\n",
    "    #Filter dataset\n",
    "    filtered_dataset = dataset[dataset['business_name'] == attributes['business_name']]\n",
    "    num_rows = filtered_dataset.shape[0]\n",
    "\n",
    "    #Pick reviews\n",
    "    if num_rows >= num_draws:\n",
    "        sampled_rows = filtered_dataset.sample(n=num_draws, replace=False)\n",
    "    else:\n",
    "        sampled_rows = filtered_dataset.sample(n=num_rows, replace=False)\n",
    "\n",
    "    examples = []\n",
    "    for _, row in sampled_rows.iterrows():\n",
    "        d = {'business_name': row['business_name'], 'stars': row['stars'], 'text_length': row['text_length'], 'text': row['text']}\n",
    "        examples.append(d)\n",
    "\n",
    "    return examples\n",
    "\n",
    "def generate_fake_review_prompt(dataset: pd.DataFrame,\n",
    "                                base_prompt: str,\n",
    "                                num_shots: int,\n",
    "                                attributes: dict) -> str:\n",
    "    \"\"\"\n",
    "    Takes review characteristics and outputs a fake review.\n",
    "    \n",
    "    Inputs:\n",
    "        - base_prompt (str): standard prompt to build from\n",
    "        - num_shots (int): number of examples to give in prompt\n",
    "        - review_length (int): max number of words contained in review\n",
    "        - restaurant (str): name of the restaurant that is getting reviewed\n",
    "        - num_stars (int): rating of the restaurant by the (fake) user\n",
    "        - useful (boolean): True if review is useful, False otherwise \n",
    "        - funny (boolean): True if review is funny, False otherwise\n",
    "        - cool (boolean):  True if review is cool, False otherwise  \n",
    "\n",
    "    Returns a prompt to generate fake review in ChatGPT's API.\n",
    "    \"\"\"\n",
    "\n",
    "    #Build prompt based on relevant variables\n",
    "    prompt = base_prompt.replace(\"REST_NAME\", attributes['business_name']) \\\n",
    "                        .replace(\"NUM_CHAR\", str(abs(attributes['text_length']))) \\\n",
    "                        .replace(\"NUM_STARS\", str(attributes['stars']))\n",
    "    #Zero-shot\n",
    "    if num_shots == 0:\n",
    "        return prompt\n",
    "    \n",
    "    #Few-shot\n",
    "    reviews = draw_reviews_from_verified_sample(dataset, num_shots, attributes)\n",
    "    few_shot_text = '\\n\\nConsider the examples below:\\n\\n'\n",
    "    count = 1\n",
    "    for i in range(len(reviews)):\n",
    "        few_shot_text += f\"##\\nExample {count}: Restaurant name = {reviews[i]['business_name']}; \" \\\n",
    "                        f\"Number of characters = {str(len(reviews[i]))}; \" \\\n",
    "                        f\"Number of stars = {str(reviews[i]['stars'])}.\\n\" \\\n",
    "                        f\"Review {count}: {reviews[i]['text']}.\\n##\"\n",
    "        count +=1\n",
    "\n",
    "    prompt = prompt+few_shot_text\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def make_api_calls(model: str, \n",
    "                  system_content: str, \n",
    "                  temperature: float, \n",
    "                  num_shots: int,\n",
    "                  dataset: pd.DataFrame\n",
    "                  ):\n",
    "    \"\"\"\n",
    "    Make calls to ChatGPT's API using a specific prompt, model, and temperature.\n",
    "\n",
    "    Inputs:\n",
    "        - model (str): model of OpenAI to use\n",
    "        - system_content (str): content of system role\n",
    "        - temperature (float): level of randomness of output\n",
    "        - num_shots (int): number of examples in prompt\n",
    "        - dataset (pd.DataFrame): DataFrame containing the dataset\n",
    "    \n",
    "    Returns a csv file where each row contains the statement and the output.\n",
    "    \"\"\"\n",
    "\n",
    "    fake_review_count = 0\n",
    "\n",
    "    if num_shots == 0:\n",
    "        shots = 'zero'\n",
    "    else:\n",
    "        shots = 'few'\n",
    "\n",
    "    attr_moments = find_moments_of_attribute_distribution(dataset)\n",
    "    attr_fake = create_fake_review_attributes(dataset, attr_moments)\n",
    "    fake_prompt = generate_fake_review_prompt(dataset, base_prompt, num_shots, attr_fake)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    csv_file_path = os.path.join(output_dir, f'fake_reviews_{model}_{num_shots}_shots.csv')\n",
    "\n",
    "    with open(csv_file_path, mode='w', newline='') as f:\n",
    "\n",
    "        # Create headers only if the file is empty\n",
    "        if os.stat(csv_file_path).st_size == 0:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"REVIEW\", \"LABEL\", \"MODEL\", \"NUM_SHOTS\"])\n",
    "\n",
    "        print('Starting API call')\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "            # Send request\n",
    "                # completion = openai.ChatCompletion.create(\n",
    "                print('model', model)\n",
    "                print('system', system_content)\n",
    "                print('prompt', fake_prompt)\n",
    "                completion = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{'role': 'system', 'content': system_content,\n",
    "                        'role': 'user', 'content': fake_prompt}],\n",
    "                temperature=temperature)\n",
    "\n",
    "                # Retrieve response\n",
    "                response = completion['choices'][0]['message']['content']\n",
    "                print(completion)\n",
    "                \n",
    "                break  # Break out of the loop if API call is successful\n",
    "            \n",
    "            except:\n",
    "                print('got and erro')\n",
    "            # except APIException as e:\n",
    "            #     print(f\"APIRemovedInV1 error: {e}\")\n",
    "            # except client.APIError as e:\n",
    "            #     print(\"API error. Retrying... (if error persists, check status.openai.com)\")\n",
    "            #     time.sleep(10)\n",
    "            # except client.Timeout as e:\n",
    "            #     print(\"Request timed out. Retrying... (if error persists, check internet connection)\")\n",
    "            #     time.sleep(5)\n",
    "            # except client.RateLimitError as e:\n",
    "            #     print(\"Reached rate limit. Retrying... (if error persists, check number of tokens/requests)\")\n",
    "            #     time.sleep(60)\n",
    "            # except client.APIConnectionError as e:\n",
    "            #     print(\"API connection error. Retrying... (if error persists, check network/proxy config/ssl/firewall)\")\n",
    "            #     time.sleep(5)\n",
    "            # except client.InvalidRequestError as e:\n",
    "            #     print(\"Invalid request error. Retrying... (if error persists, check for invalid/missing request parameters)\")\n",
    "            # except client.AuthenticationError as e:\n",
    "            #     print(\"Authentication error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "            # except client.ServiceUnavailableError as e:\n",
    "            #     print(\"Server is overloaded. Retrying... (if error persists, check status.openai.com)\")\n",
    "            #     time.sleep(120)\n",
    "\n",
    "        # Write csv file\n",
    "        writer.writerow([response, \"FAKE\", model, shots])\n",
    "        print(f'Progress: {round(fake_review_count/len(dataset),2)*100}%')\n",
    "        fake_review_count +=1\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    return print(\"API calls complete\")\n",
    "\n",
    "# def make_api_calls(model: str, \n",
    "#                   system_content: str, \n",
    "#                   temperature: float, \n",
    "#                   num_shots: int,\n",
    "#                   dataset: pd.DataFrame\n",
    "#                   ):\n",
    "#     \"\"\"\n",
    "#     Make calls to ChatGPT's API using a specific prompt, model and temperature.\n",
    "\n",
    "#     Inputs:\n",
    "#         - model (str): model of OpenAI to use\n",
    "#         - system_content (str): content of system role\n",
    "#         - temperature (float): level of randomness of output\n",
    "#         - prompt (str): prompt to feed to the model\n",
    "#         - num_shots (int): number of examples in prompt\n",
    "    \n",
    "#     Returns a csv file where each row contains the statement and the output.\n",
    "#     \"\"\"\n",
    "\n",
    "#     fake_review_count = 0\n",
    "\n",
    "#     if num_shots == 0:\n",
    "#         shots = 'zero'\n",
    "#     else:\n",
    "#         shots = 'few'\n",
    "\n",
    "#     attr_moments = find_moments_of_attribute_distribution(dataset)\n",
    "#     attr_fake = create_fake_review_attributes(dataset, attr_moments)\n",
    "#     fake_prompt = generate_fake_review_prompt(dataset, base_prompt, num_shots, attr_fake)\n",
    "\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     csv_file_path = os.path.join(output_dir, f'fake_reviews_{model}_{num_shots}_shots.csv')\n",
    "\n",
    "#     with open(csv_file_path, mode='w', newline='') as f:\n",
    "\n",
    "#         # Create headers only if the file is empty\n",
    "#         if os.stat(csv_file_path).st_size == 0:\n",
    "#             writer = csv.writer(f)\n",
    "#             writer.writerow([\"REVIEW\", \"LABEL\", \"MODEL\", \"NUM_SHOTS\"])\n",
    "\n",
    "#         print('Starting API call')\n",
    "\n",
    "#         # API call\n",
    "#         while True:\n",
    "#             try:\n",
    "#             # Send request\n",
    "#                 completion = openai.ChatCompletion.create(\n",
    "#             # completion = client.chat.completions.create(\n",
    "#                 model=model,\n",
    "#                 messages=[{'role': 'system', 'content': system_content,\n",
    "#                         'role': 'user', 'content': fake_prompt}],\n",
    "#                 temperature=temperature)\n",
    "\n",
    "#                 # Retrieve response\n",
    "#                 response = completion['choices'][0]['message']['content']\n",
    "#                 break  # Break out of the loop if API call is successful\n",
    "\n",
    "#             #Handle errors\n",
    "#             # except:\n",
    "#             #     print(\"API error, trying again\")\n",
    "#             #     time.sleep(10)\n",
    "\n",
    "#             except openai.error.APIError as e:\n",
    "#                 print(\"API error. Retrying... (if error persists, check status.openai.com)\")\n",
    "#                 time.sleep(10)\n",
    "#             except openai.error.Timeout as e:\n",
    "#                 print(\"Request timed out. Retrying... (if error persists, check internet connection)\")\n",
    "#                 time.sleep(5)\n",
    "#             except openai.error.RateLimitError as e:\n",
    "#                 print(\"Reached rate limit. Retrying... (if error persists, check number of tokens/requests)\")\n",
    "#                 time.sleep(60)\n",
    "#             except openai.error.APIConnectionError as e:\n",
    "#                 print(\"API connection error. Retrying... (if error persists, check network/proxy config/ssl/firewall)\")\n",
    "#                 time.sleep(5)\n",
    "#             except openai.error.InvalidRequestError as e:\n",
    "#                 print(\"Invalid request error. Retrying... (if error persists, check for invalid/missing request parameters)\")\n",
    "#             except openai.error.AuthenticationError as e:\n",
    "#                 print(\"Authentication error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             except openai.error.ServiceUnavailableError as e:\n",
    "#                 print(\"Server is overloaded. Retrying... (if error persists, check status.openai.com)\")\n",
    "#                 time.sleep(120)\n",
    "\n",
    "#             #Handle errors\n",
    "#             # except:\n",
    "#             #     print(\"API error, trying again\")\n",
    "\n",
    "#             # except OpenAI.error.APIConnectionError as e:\n",
    "#             #     print(\"API connection error. Retrying... (if error persists, check network/proxy config/ssl/firewall)\")\n",
    "#             #     time.sleep(5)\n",
    "#             # except OpenAI.error.TimeoutError as e:\n",
    "#             #     print(\"Request timed out. Retrying... (if error persists, check internet connection)\")\n",
    "#             #     time.sleep(5)\n",
    "#             # except OpenAI.error.AuthenticationError as e:\n",
    "#             #     print(\"Authentication error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.BadRequestError as e:\n",
    "#             #     print(\"Bad request error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.ConflictError as e:\n",
    "#             #     print(\"Conflict error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.InternalServerError as e:\n",
    "#             #     print(\"Internal server error error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.NotFoundError as e:\n",
    "#             #     print(\"Not found error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.PermissionDeniedError as e:\n",
    "#             #     print(\"Permission denied error. Retrying... (if error persists, check for invalid/expired/revoked API key or token)\")\n",
    "#             # except OpenAI.error.RateLimitError as e:\n",
    "#             #     print(\"Reached rate limit. Retrying... (if error persists, check number of tokens/requests)\")\n",
    "#             #     time.sleep(60)\n",
    "#             # except OpenAI.UnprocessableEntityError as e:\n",
    "#             #     print(\"Unprocessable entity error. Retrying... (if error persists, check for invalid/missing request parameters)\")\n",
    "\n",
    "#         # Write csv file\n",
    "#         writer.writerow([response, \"FAKE\", model, shots])\n",
    "#         print(f'Progress: {round(fake_review_count/len(dataset),2)*100}%')\n",
    "#         fake_review_count +=1\n",
    "\n",
    "#     f.close()\n",
    "    \n",
    "#     return print(\"API calls complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>comment_year</th>\n",
       "      <th>business_name</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UlPCp6kFGGUSKycc5kNiJg</td>\n",
       "      <td>PSA: CASH ONLY!! \\n\\nA hole in the wall family...</td>\n",
       "      <td>2019-11-13 14:25:16</td>\n",
       "      <td>d48Xrx8MhGtdaLvhcYzNWQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019,20,20,2021</td>\n",
       "      <td>2019</td>\n",
       "      <td>Cafe Diem</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2ZKf-CjGthLamYKNAcbJw</td>\n",
       "      <td>When you're craving empanadas, check out this ...</td>\n",
       "      <td>2019-11-09 19:40:02</td>\n",
       "      <td>ngU4740twiB222g4ti0_eQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019,20,20,2021</td>\n",
       "      <td>2019</td>\n",
       "      <td>Cocina Latina</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9fOezqmM4pYOHCcPD1C0aA</td>\n",
       "      <td>Loved our cheesesteaks. By the length of the l...</td>\n",
       "      <td>2019-12-03 17:15:01</td>\n",
       "      <td>8xTHtLoNIwdpf0FEvIpQIw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015,2016,2017,2018,2019,20,20,2021</td>\n",
       "      <td>2019</td>\n",
       "      <td>By George! Pizza Pasta &amp; Cheesesteaks</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UHuNFy-CDLj_SVMOQBHryw</td>\n",
       "      <td>Such fun! Great experience. Chef was terrific....</td>\n",
       "      <td>2021-09-25 14:35:27</td>\n",
       "      <td>29sZgoR7VN_3ck3NF5easg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20,20,2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>Izakaya Japanese Bar &amp; Grill</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DbiZXAui0L2LGHB5E0blrw</td>\n",
       "      <td>Really cool spot in Northern Liberties. Weathe...</td>\n",
       "      <td>2018-08-24 16:36:13</td>\n",
       "      <td>JUlsvVAvZvGHWFfkKm0nlg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018,2019</td>\n",
       "      <td>2018</td>\n",
       "      <td>El Camino Real</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id                                               text  \\\n",
       "0  UlPCp6kFGGUSKycc5kNiJg  PSA: CASH ONLY!! \\n\\nA hole in the wall family...   \n",
       "1  t2ZKf-CjGthLamYKNAcbJw  When you're craving empanadas, check out this ...   \n",
       "2  9fOezqmM4pYOHCcPD1C0aA  Loved our cheesesteaks. By the length of the l...   \n",
       "3  UHuNFy-CDLj_SVMOQBHryw  Such fun! Great experience. Chef was terrific....   \n",
       "4  DbiZXAui0L2LGHB5E0blrw  Really cool spot in Northern Liberties. Weathe...   \n",
       "\n",
       "                  date             business_id  stars  useful  funny  cool  \\\n",
       "0  2019-11-13 14:25:16  d48Xrx8MhGtdaLvhcYzNWQ    5.0       0      0     0   \n",
       "1  2019-11-09 19:40:02  ngU4740twiB222g4ti0_eQ    5.0       0      0     0   \n",
       "2  2019-12-03 17:15:01  8xTHtLoNIwdpf0FEvIpQIw    5.0       0      0     0   \n",
       "3  2021-09-25 14:35:27  29sZgoR7VN_3ck3NF5easg    5.0       0      0     0   \n",
       "4  2018-08-24 16:36:13  JUlsvVAvZvGHWFfkKm0nlg    5.0       0      0     0   \n",
       "\n",
       "                                 elite  comment_year  \\\n",
       "0                      2019,20,20,2021          2019   \n",
       "1                      2019,20,20,2021          2019   \n",
       "2  2015,2016,2017,2018,2019,20,20,2021          2019   \n",
       "3                           20,20,2021          2021   \n",
       "4                            2018,2019          2018   \n",
       "\n",
       "                           business_name  text_length  \n",
       "0                              Cafe Diem          622  \n",
       "1                          Cocina Latina          235  \n",
       "2  By George! Pizza Pasta & Cheesesteaks          261  \n",
       "3           Izakaya Japanese Bar & Grill          265  \n",
       "4                         El Camino Real          975  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "data = pd.read_csv('data/yelp/yelp_verified_slim.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11106"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attr_moments = find_moments_of_attribute_distribution(data)\n",
    "# attr_fake = create_fake_review_attributes(data, attr_moments)\n",
    "# print(attr_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_shots=3\n",
    "# reviews = draw_reviews_from_verified_sample(data, num_shots, attr_fake)\n",
    "# for r in reviews:\n",
    "#     print(r)\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You attended a restaurant named Mi Nidito Restaurant.\n",
      "You rated your experience with 5 stars out of 5.\n",
      "Write a review of 137 characters describing your experience.\n",
      "\n",
      "Consider the examples below:\n",
      "\n",
      "##\n",
      "Example 1: Restaurant name = Mi Nidito Restaurant; Number of characters = 4; Number of stars = 2.0.\n",
      "Review 1: OK, been a while, but that is because I was not impressed.  The ambiance of the decor is about the best thing going for it.  I truly do not know why this place is constantly packed to the brim with folks.  Nor do I understand why anyone would wait an hour plus to be seated.  A restaurant would have to be absolutely incredible, plus have seating at a bar for me to wait that long.  Speaking of seating, there are two small benches for those waiting to be seated.  Don't expect to find a place to sit, in other words.  All that aside, it is about the food, right?  I mean, the place is packed.  Clinton liked it.  Willie Nelson liked it.  Other celebrities liked it.  SO it's got to be good, right?  Nope.  Mediocre at best.  And certainly not worth the wait.  Upon a recommendation from a friend, I left there last time I tried to get in and headed down the road a little to Las Cazuelitas (now at 22nd and Country Club, plus a couple other locations around town).  No wait to be seated.  Nice ambiance.  A bar.  Much, much better food, with a larger selection.  \n",
      "If you need to feel empowered by going where some celebrities have gone, then by all means, deal with the hour plus wait for fancy taco bell.  If you just want good Mexican, go almost anywhere else.  Or don't.  Then I can keep walking in to the places I frequent and get a seat right away..\n",
      "####\n",
      "Example 2: Restaurant name = Mi Nidito Restaurant; Number of characters = 4; Number of stars = 4.0.\n",
      "Review 2: I enjoyed my chicken enchiladas (the pulled chicken was moist and flavorful), the chips were crispy and the salsa was good.  Service was indeed friendly and the ambiance was perfect for the food.  Bathrooms were clean and when I'm back in Tucson will try again.  Wait time for food was longer than it should have been..\n",
      "####\n",
      "Example 3: Restaurant name = Mi Nidito Restaurant; Number of characters = 4; Number of stars = 4.0.\n",
      "Review 3: After I finally found them hidden on a side street I luckily only had to wait 5 or so minutes for a table.  Although the restaurant was crowded and busy the service was still good, if a little slow.  The restaurant is fairly small so the seating is pretty close together so this would probably not be the best place to be private or have a conversation that you don't want overheard.  I ordered the Green Chili Enchiladas and they were amazing.  Why do places in California not use green chili like they do in Arizona and New Mexico??  It is seriously delicious.  So anyhow, yes the enchiladas were tasty and cheesy and I wish I could eat about 100 of them.  This was my favorite meal I had while in Tucson..\n",
      "##\n"
     ]
    }
   ],
   "source": [
    "num_shots=3\n",
    "attr_moments = find_moments_of_attribute_distribution(data)\n",
    "attr_fake = create_fake_review_attributes(data, attr_moments)\n",
    "fake_prompt = generate_fake_review_prompt(data, base_prompt, num_shots, attr_fake)\n",
    "print(fake_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting API call\n",
      "model gpt-3.5-turbo-16k-0613\n",
      "system You are a person that writes restaurant reviews\n",
      "prompt You attended a restaurant named El Molinito.\n",
      "You rated your experience with 5 stars out of 5.\n",
      "Write a review of 1366 characters describing your experience.\n",
      "got and erro\n",
      "model gpt-3.5-turbo-16k-0613\n",
      "system You are a person that writes restaurant reviews\n",
      "prompt You attended a restaurant named El Molinito.\n",
      "You rated your experience with 5 stars out of 5.\n",
      "Write a review of 1366 characters describing your experience.\n",
      "got and erro\n",
      "model gpt-3.5-turbo-16k-0613\n",
      "system You are a person that writes restaurant reviews\n",
      "prompt You attended a restaurant named El Molinito.\n",
      "You rated your experience with 5 stars out of 5.\n",
      "Write a review of 1366 characters describing your experience.\n",
      "got and erro\n",
      "model gpt-3.5-turbo-16k-0613\n",
      "system You are a person that writes restaurant reviews\n",
      "prompt You attended a restaurant named El Molinito.\n",
      "You rated your experience with 5 stars out of 5.\n",
      "Write a review of 1366 characters describing your experience.\n",
      "got and erro\n",
      "model gpt-3.5-turbo-16k-0613\n",
      "system You are a person that writes restaurant reviews\n",
      "prompt You attended a restaurant named El Molinito.\n",
      "You rated your experience with 5 stars out of 5.\n",
      "Write a review of 1366 characters describing your experience.\n",
      "got and erro\n",
      "model gpt-3.5-turbo-16k-0613\n",
      "system You are a person that writes restaurant reviews\n",
      "prompt You attended a restaurant named El Molinito.\n",
      "You rated your experience with 5 stars out of 5.\n",
      "Write a review of 1366 characters describing your experience.\n"
     ]
    }
   ],
   "source": [
    "make_api_calls(model='gpt-3.5-turbo-16k-0613', \n",
    "               system_content='You are a person that writes restaurant reviews', \n",
    "               temperature=1.0, \n",
    "               num_shots=0,\n",
    "               dataset= pd.read_csv('data/yelp/yelp_verified_slim.csv')\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset for API calls\n",
    "part_size = len(data) // 3\n",
    "\n",
    "#Jack\n",
    "make_api_calls(model='gpt-4-1106-preview', \n",
    "               system_content='You are a person that writes restaurant reviews', \n",
    "               temperature=1.0, \n",
    "               num_shots=3,\n",
    "               dataset= data.iloc[:part_size]\n",
    "               )\n",
    "\n",
    "#Claire\n",
    "make_api_calls(model='gpt-3.5-turbo-16k-0613', \n",
    "               system_content='You are a person that writes restaurant reviews', \n",
    "               temperature=1.0, \n",
    "               num_shots=3,\n",
    "               dataset= data.iloc[part_size:2 * part_size]\n",
    "               )\n",
    "\n",
    "#Benja\n",
    "make_api_calls(model='gpt-3.5-turbo-16k-0613', \n",
    "               system_content='You are a person that writes restaurant reviews', \n",
    "               temperature=1.0, \n",
    "               num_shots=0,\n",
    "               dataset= data.iloc[part_size:2 * part_size]\n",
    "               )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "85ea4b3f8f8bbee1e23da4c155a93a1e9f6833b5217ca791a452f768bdc9cb7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
